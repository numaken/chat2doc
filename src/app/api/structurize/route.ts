import { NextRequest, NextResponse } from 'next/server'
import { getServerSession } from 'next-auth'
import OpenAI from 'openai'

interface StructuredData {
  purpose: string
  progress: string[]
  challenges: string[]
  nextActions: string[]
  code?: Array<{
    fileName?: string
    description?: string
    snippet?: string
  }>
  intentions?: string[]
  concerns?: string[]
}

// ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿è­·: APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
const apiKey = process.env.OPENAI_API_KEY || process.env.OPENAI_API_KEY_SHARED

if (!apiKey || apiKey === 'disabled_for_security_reasons') {
  console.warn('ğŸ›¡ï¸ OpenAI APIç„¡åŠ¹åŒ– - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿è­·ä¸­')
}

const openai = new OpenAI({
  apiKey: apiKey || 'disabled',
})

export async function POST(request: NextRequest) {
  try {
    // èªè¨¼ãƒã‚§ãƒƒã‚¯: ãƒ­ã‚°ã‚¤ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿APIã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
    const session = await getServerSession()
    if (!session || !session.user) {
      return NextResponse.json(
        { 
          error: 'ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™ã€‚èªè¨¼å¾Œã«å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚',
          code: 'AUTHENTICATION_REQUIRED'
        },
        { status: 401 }
      )
    }

    // ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯: APIã‚­ãƒ¼ãŒç„¡åŠ¹ãªå ´åˆã¯ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢
    if (!apiKey || apiKey === 'disabled_for_security_reasons' || apiKey === 'disabled') {
      return NextResponse.json(
        { 
          error: 'ã‚µãƒ¼ãƒ“ã‚¹ä¸€æ™‚åœæ­¢ä¸­ã§ã™ã€‚èªè¨¼ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…å¾Œã«å†é–‹äºˆå®šã§ã™ã€‚',
          code: 'SERVICE_TEMPORARILY_DISABLED'
        },
        { status: 503 }
      )
    }

    const { conversationText } = await request.json()

    if (!conversationText || !conversationText.trim()) {
      return NextResponse.json(
        { error: 'ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦ã§ã™' },
        { status: 400 }
      )
    }

    // ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®šç¾©
    const systemPrompt = `ã‚ãªãŸã¯é–‹ç™ºè€…å‘ã‘ã®ä¼šè©±ãƒ­ã‚°åˆ†æAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ä»¥ä¸‹ã®ä¼šè©±ãƒ­ã‚°ã‚’åˆ†æã—ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®çŠ¶æ³ã‚’ä»¥ä¸‹ã®7ã¤ã®ã‚«ãƒ†ã‚´ãƒªã«æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ï¼š

1. ç›®çš„ï¼ˆpurposeï¼‰: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®çš„ã‚„ç›®æ¨™ã‚’1æ–‡ã§ç°¡æ½”ã«
2. å¯¾å¿œå±¥æ­´ï¼ˆprogressï¼‰: å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã‚„å®Ÿè£…æ¸ˆã¿ã®æ©Ÿèƒ½ã‚’ç®‡æ¡æ›¸ãã§
3. èª²é¡Œï¼ˆchallengesï¼‰: ç¾åœ¨ç›´é¢ã—ã¦ã„ã‚‹å•é¡Œã‚„æœªè§£æ±ºã®èª²é¡Œã‚’ç®‡æ¡æ›¸ãã§
4. æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆnextActionsï¼‰: æ¬¡ã«å–ã‚Šçµ„ã‚€ã¹ãå…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç®‡æ¡æ›¸ãã§
5. ã‚³ãƒ¼ãƒ‰ï¼ˆcodeï¼‰: ä¼šè©±ä¸­ã«å‡ºç¾ã—ãŸé‡è¦ãªã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‚‚å«ã‚€ï¼‰
6. æ„å›³ï¼ˆintentionsï¼‰: ãªãœãã®å®Ÿè£…ãƒ»è¨­è¨ˆã‚’é¸ã‚“ã ã®ã‹ã®ç†ç”±ã‚„èƒŒæ™¯
7. æ‡¸å¿µç‚¹ï¼ˆconcernsï¼‰: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ä¿å®ˆæ€§ãªã©ã®æŠ€è¡“çš„ãªæ‡¸å¿µäº‹é …

å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
{
  "purpose": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®çš„ã‚’1æ–‡ã§",
  "progress": [
    "å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯1",
    "å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯2"
  ],
  "challenges": [
    "èª²é¡Œ1", 
    "èª²é¡Œ2"
  ],
  "nextActions": [
    "æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³1",
    "æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³2"
  ],
  "code": [
    {
      "fileName": "ãƒ•ã‚¡ã‚¤ãƒ«å",
      "description": "ã‚³ãƒ¼ãƒ‰ã®èª¬æ˜",
      "snippet": "ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆ"
    }
  ],
  "intentions": [
    "è¨­è¨ˆæ„å›³1",
    "è¨­è¨ˆæ„å›³2"
  ],
  "concerns": [
    "æŠ€è¡“çš„æ‡¸å¿µç‚¹1",
    "æŠ€è¡“çš„æ‡¸å¿µç‚¹2"
  ]
}

ä¼šè©±ã®æ–‡è„ˆã‹ã‚‰é–‹ç™ºè€…ã«ã¨ã£ã¦ä¾¡å€¤ã®ã‚ã‚‹å…·ä½“çš„ãªæƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚`

    // é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦å‡¦ç†
    const fullText = conversationText.trim()
    const maxCharsPerChunk = 25000 // ãƒãƒ£ãƒ³ã‚¯ã‚ãŸã‚Šç´„10000ãƒˆãƒ¼ã‚¯ãƒ³ç›¸å½“
    
    if (fullText.length > maxCharsPerChunk) {
      console.log(`ğŸ“ é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¤œå‡º (${fullText.length} æ–‡å­—). ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™`)
      
      // ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
      const chunks = []
      for (let i = 0; i < fullText.length; i += maxCharsPerChunk) {
        chunks.push(fullText.substring(i, i + maxCharsPerChunk))
      }
      
      console.log(`ğŸ”„ ${chunks.length} ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸ`)
      
      // å„ãƒãƒ£ãƒ³ã‚¯ã‚’é †ç•ªã«å‡¦ç†
      const chunkResults: StructuredData[] = []
      for (let i = 0; i < chunks.length; i++) {
        console.log(`âš¡ ãƒãƒ£ãƒ³ã‚¯ ${i + 1}/${chunks.length} ã‚’å‡¦ç†ä¸­...`)
        
        const chunkCompletion = await openai.chat.completions.create({
          model: "gpt-3.5-turbo",
          messages: [
            {
              role: "system",
              content: systemPrompt + `\n\næ³¨æ„: ã“ã‚Œã¯${chunks.length}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã®${i + 1}ç•ªç›®ã§ã™ã€‚`
            },
            {
              role: "user", 
              content: `ä»¥ä¸‹ã®ä¼šè©±ãƒ­ã‚°ã®ä¸€éƒ¨ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ï¼š\n\n${chunks[i]}`
            }
          ],
          max_tokens: 1000,
          temperature: 0.3,
        })
        
        const chunkContent = chunkCompletion.choices[0]?.message?.content
        if (chunkContent) {
          try {
            const jsonMatch = chunkContent.match(/```json\s*([\s\S]*?)\s*```/)
            const jsonString = jsonMatch ? jsonMatch[1] : chunkContent
            const chunkData = JSON.parse(jsonString.trim()) as StructuredData
            
            // å¿…è¦ãªãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            if (chunkData.purpose && Array.isArray(chunkData.progress) && 
                Array.isArray(chunkData.challenges) && Array.isArray(chunkData.nextActions)) {
              chunkResults.push(chunkData)
            }
            console.log(`âœ… ãƒãƒ£ãƒ³ã‚¯ ${i + 1} å‡¦ç†å®Œäº†`)
          } catch (parseError) {
            console.error(`âŒ ãƒãƒ£ãƒ³ã‚¯ ${i + 1} ã®è§£æã‚¨ãƒ©ãƒ¼:`, parseError)
          }
        }
      }
      
      // çµæœã‚’ãƒãƒ¼ã‚¸
      console.log(`ğŸ”— ${chunkResults.length} ãƒãƒ£ãƒ³ã‚¯ã®çµæœã‚’ãƒãƒ¼ã‚¸ä¸­...`)
      const mergedResult: StructuredData = {
        purpose: chunkResults[0]?.purpose || "è¤‡æ•°ã®ä¼šè©±ãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
        progress: [],
        challenges: [],
        nextActions: [],
        code: [],
        intentions: [],
        concerns: []
      }
      
      // å„ãƒãƒ£ãƒ³ã‚¯ã®çµæœã‚’çµ±åˆï¼ˆãƒãƒ£ãƒ³ã‚¯ç•ªå·ã¯ä»˜ã‘ãªã„ï¼‰
      chunkResults.forEach((chunk) => {
        if (chunk.progress) mergedResult.progress.push(...chunk.progress)
        if (chunk.challenges) mergedResult.challenges.push(...chunk.challenges)
        if (chunk.nextActions) mergedResult.nextActions.push(...chunk.nextActions)
        if (chunk.code && mergedResult.code) mergedResult.code.push(...chunk.code)
        if (chunk.intentions && mergedResult.intentions) mergedResult.intentions.push(...chunk.intentions)
        if (chunk.concerns && mergedResult.concerns) mergedResult.concerns.push(...chunk.concerns)
      })
      
      // é‡è¤‡é™¤å»ã¨æ•´ç†
      mergedResult.progress = [...new Set(mergedResult.progress)]
      mergedResult.challenges = [...new Set(mergedResult.challenges)]
      mergedResult.nextActions = [...new Set(mergedResult.nextActions)]
      if (mergedResult.intentions) mergedResult.intentions = [...new Set(mergedResult.intentions)]
      if (mergedResult.concerns) mergedResult.concerns = [...new Set(mergedResult.concerns)]
      // codeã¯æ§‹é€ ãŒç•°ãªã‚‹ãŸã‚é‡è¤‡é™¤å»ã—ãªã„
      
      console.log(`ğŸ¯ ãƒãƒ¼ã‚¸å®Œäº†:`, {
        purpose: mergedResult.purpose.substring(0, 50) + '...',
        progressCount: mergedResult.progress.length,
        challengesCount: mergedResult.challenges.length,
        nextActionsCount: mergedResult.nextActions.length,
        codeCount: mergedResult.code?.length || 0,
        intentionsCount: mergedResult.intentions?.length || 0,
        concernsCount: mergedResult.concerns?.length || 0
      })
      
      return NextResponse.json({
        success: true,
        structuredData: mergedResult,
        metadata: {
          model: 'gpt-3.5-turbo',
          chunks: chunks.length,
          totalChars: fullText.length,
          timestamp: new Date().toISOString()
        }
      })
    }

    // é€šå¸¸ã®å‡¦ç†ï¼ˆ25,000æ–‡å­—ä»¥ä¸‹ã®å ´åˆï¼‰
    console.log('ğŸ¤– OpenAI APIå‘¼ã³å‡ºã—é–‹å§‹')
    console.log('ğŸ“ å‡¦ç†æ–‡å­—æ•°:', fullText.length)

    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: systemPrompt
        },
        {
          role: "user", 
          content: `ä»¥ä¸‹ã®ä¼šè©±ãƒ­ã‚°ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ï¼š\n\n${fullText}`
        }
      ],
      max_tokens: 1000,
      temperature: 0.3, // ã‚ˆã‚Šä¸€è²«æ€§ã®ã‚ã‚‹å‡ºåŠ›ã®ãŸã‚ä½ã‚ã«è¨­å®š
    })

    const responseContent = completion.choices[0]?.message?.content
    console.log('âœ… OpenAI APIãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡')

    if (!responseContent) {
      throw new Error('OpenAI APIã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã™')
    }

    // JSONã®æŠ½å‡ºã‚’è©¦ã¿ã‚‹ï¼ˆ```json ``` ã§å›²ã¾ã‚Œã¦ã„ã‚‹å ´åˆã«å¯¾å¿œï¼‰
    let structuredData: StructuredData
    try {
      // JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
      const jsonMatch = responseContent.match(/```json\s*([\s\S]*?)\s*```/)
      const jsonString = jsonMatch ? jsonMatch[1] : responseContent
      
      structuredData = JSON.parse(jsonString.trim()) as StructuredData
      
      // å¿…è¦ãªãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
      if (!structuredData.purpose || !Array.isArray(structuredData.progress) || 
          !Array.isArray(structuredData.challenges) || !Array.isArray(structuredData.nextActions)) {
        throw new Error('Invalid structure')
      }

    } catch (parseError) {
      console.error('âŒ JSONè§£æã‚¨ãƒ©ãƒ¼:', parseError)
      console.log('ğŸ“„ å…ƒã®å¿œç­”:', responseContent)
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡å˜ãªæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
      structuredData = {
        purpose: "ä¼šè©±ãƒ­ã‚°ã®æ§‹é€ åŒ–ãŒéƒ¨åˆ†çš„ã«å®Œäº†ã—ã¾ã—ãŸ",
        progress: ["AIã«ã‚ˆã‚‹ä¼šè©±åˆ†æã‚’å®Ÿè¡Œ"],
        challenges: ["JSONå½¢å¼ã§ã®å®Œå…¨ãªæ§‹é€ åŒ–ã«èª²é¡ŒãŒç™ºç”Ÿ"],
        nextActions: ["æ‰‹å‹•ã§ã®æ§‹é€ åŒ–çµæœã®ç¢ºèªã¨èª¿æ•´ãŒå¿…è¦"],
        code: [],
        intentions: [],
        concerns: []
      }
    }

    console.log('ğŸ¯ æ§‹é€ åŒ–å®Œäº†:', {
      purpose: structuredData.purpose.substring(0, 50) + '...',
      progressCount: structuredData.progress.length,
      challengesCount: structuredData.challenges.length, 
      nextActionsCount: structuredData.nextActions.length,
      codeCount: structuredData.code?.length || 0,
      intentionsCount: structuredData.intentions?.length || 0,
      concernsCount: structuredData.concerns?.length || 0
    })

    // ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’ãƒ­ã‚°å‡ºåŠ›
    console.log('ğŸ’° ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡:', {
      prompt: completion.usage?.prompt_tokens,
      completion: completion.usage?.completion_tokens,
      total: completion.usage?.total_tokens
    })

    return NextResponse.json({
      success: true,
      structuredData,
      metadata: {
        model: 'gpt-3.5-turbo',
        tokens: completion.usage?.total_tokens,
        timestamp: new Date().toISOString()
      }
    })

  } catch (error) {
    console.error('âŒ API Error:', error)
    
    if (error instanceof Error && error.message.includes('API key')) {
      return NextResponse.json(
        { error: 'OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“' },
        { status: 500 }
      )
    }

    return NextResponse.json(
      { error: 'ä¼šè©±ã®æ§‹é€ åŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ' },
      { status: 500 }
    )
  }
}